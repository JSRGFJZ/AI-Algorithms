{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1851\n",
      "(1851,)   (1851, 86)\n"
     ]
    }
   ],
   "source": [
    "#mainly https://machinelearningmastery.com/feature-selection-in-python-with-scikit-learn/\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import pandas\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "# prepare my dataset\n",
    "file_path = \"./original_train_and_test\"\n",
    "f = open(file_path, 'r')\n",
    "# get whole line data\n",
    "lists = []\n",
    "for line in f.readlines():\n",
    "    list_split = line.rstrip('\\n').rstrip(' ')\n",
    "    lists.append(list_split)\n",
    "# split, no need to split first one\n",
    "print(len(lists))\n",
    "train_file = []\n",
    "for i in range(len(lists)):\n",
    "    # for every line, we split\n",
    "    temp_line = lists[i]\n",
    "    temp_line = temp_line.split(\" \")\n",
    "    data = []\n",
    "    #in one line, after first column\n",
    "    for j in range(len(temp_line)):\n",
    "        # split this, mainly \"2:33\", like this\n",
    "        temp_line_column = temp_line[j]\n",
    "        temp_line_column = temp_line_column.split(\":\")\n",
    "        data.append(np.double(temp_line_column[-1]))\n",
    "    train_file.append(data)\n",
    "f.close()\n",
    "train_file=np.array(train_file)\n",
    "data = train_file[:,1:]\n",
    "target = train_file[:,0]\n",
    "print(np.shape(target),\" \", np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (768, 9)\n"
     ]
    }
   ],
   "source": [
    "# prepare dataset\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "print(\"data shape: \",np.shape(array))\n",
    "X= array[:,0:8]\n",
    "Y=array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "[False  True  True  True]\n",
      "[2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#recursive feature elimination\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(dataset.data, dataset.target)\n",
    "print(np.shape(dataset.data))\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True  True  True  True  True  True  True False False  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True False False\n",
      " False  True False False False False False  True  True False False False\n",
      " False False  True  True  True  True  True False  True  True False  True\n",
      " False False  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False]\n",
      "[17  1  1  1  1  1  1  1  1 23 16  1 21  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1 18 10 20  1 14 22 15  7 12  1  1 13  9 11 19  4\n",
      "  1  1  1  1  1  2  1  1  3  1  5  8  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  6]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 64)\n",
    "rfe = rfe.fit(data, target)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n",
      "[ 0.117  0.068  0.403  0.412]\n"
     ]
    }
   ],
   "source": [
    "#feature importance\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "dataset = datasets.load_iris()\n",
    "print(np.shape(dataset.data), np.shape(dataset.target))\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(dataset.data, dataset.target)\n",
    "\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/feature-selection-machine-learning-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  111.52   1411.887    17.605    53.108  2175.565   127.669     5.393\n",
      "   181.304]\n",
      "[[  6.000e+00   1.480e+02   7.200e+01   3.500e+01   0.000e+00   3.360e+01\n",
      "    6.270e-01   5.000e+01]\n",
      " [  1.000e+00   8.500e+01   6.600e+01   2.900e+01   0.000e+00   2.660e+01\n",
      "    3.510e-01   3.100e+01]\n",
      " [  8.000e+00   1.830e+02   6.400e+01   0.000e+00   0.000e+00   2.330e+01\n",
      "    6.720e-01   3.200e+01]\n",
      " [  1.000e+00   8.900e+01   6.600e+01   2.300e+01   9.400e+01   2.810e+01\n",
      "    1.670e-01   2.100e+01]\n",
      " [  0.000e+00   1.370e+02   4.000e+01   3.500e+01   1.680e+02   4.310e+01\n",
      "    2.288e+00   3.300e+01]]\n",
      "[[ 148.    0.   50.]\n",
      " [  85.    0.   31.]\n",
      " [ 183.    0.   32.]\n",
      " [  89.   94.   21.]\n",
      " [ 137.  168.   33.]]\n"
     ]
    }
   ],
   "source": [
    "#univariate selection\n",
    "import pandas\n",
    "import numpy\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#feature extraction\n",
    "test = SelectKBest(score_func = chi2, k=3)\n",
    "fit = test.fit(X, Y)\n",
    "# fit = test.fit(dataset.data, dataset.target)\n",
    "# summarize scores\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "features = fit.transform(X)\n",
    "print(X[0:5,:])\n",
    "#after transformation, just select those features that have maximum scores\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of features: 3\n",
      "selected features: [ True False False False False  True  True False]\n",
      "feature ranking: [1 2 3 5 6 1 1 4]\n"
     ]
    }
   ],
   "source": [
    "# recursive feature elimination\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, Y)\n",
    "print((\"num of features: %d\")%fit.n_features_)\n",
    "print((\"selected features: %s\")%fit.support_)\n",
    "print((\"feature ranking: %s\")%fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.889  0.062  0.026]\n",
      "[ 3212.661   845.829   547.333]\n"
     ]
    }
   ],
   "source": [
    "# pca learning\n",
    "\n",
    "\n",
    "# pca\n",
    "import numpy\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca= PCA(n_components = 3)\n",
    "fit=pca.fit(X)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.117  0.223  0.104  0.082  0.071  0.139  0.11   0.154]\n"
     ]
    }
   ],
   "source": [
    "# feature importance\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, Y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "#  this is overall method\n",
    "## http://scikit-learn.org/stable/modules/feature_selection.html\n",
    "\n",
    "- remove features with low variances\n",
    "- univariate feature selection\n",
    "- Recursive feature elimination\n",
    "- feature selection using SelectFromModel\n",
    "    - L1- based feature selection\n",
    "    - tree-based feature selection\n",
    "- sfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 1]\n",
      " [0 1 0]\n",
      " [0 1 1]]\n",
      "(6, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove features with low variances\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "X = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "print(np.array(X))\n",
    "print(np.shape(X))\n",
    "sel=VarianceThreshold()\n",
    "# sel=VarianceThreshold(threshold=(0.8*(1-0.8)))\n",
    "sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]]\n",
      "(150, 2)\n",
      "[[ 1.4  0.2]\n",
      " [ 1.4  0.2]\n",
      " [ 1.3  0.2]\n",
      " [ 1.5  0.2]\n",
      " [ 1.4  0.2]]\n"
     ]
    }
   ],
   "source": [
    "# univariate feature selection\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "iris = load_iris()\n",
    "X,y = iris.data, iris.target\n",
    "print(X.shape)\n",
    "print(X[0:5,:])\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(X,y)\n",
    "print(X_new.shape)\n",
    "print(X_new[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "[False  True  True  True]\n",
      "[2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Recursive feature elimination, no cross validation\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(dataset.data, dataset.target)\n",
    "print(np.shape(dataset.data))\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of best features: 3\n",
      "feature size: (25,), support: [False  True False False False False False  True False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 5,  1, 12, 19, 15,  6, 17,  1,  2, 21, 23, 11, 16, 10, 13, 22,  8,\n",
       "       14,  1, 20,  7,  9,  3,  4, 18])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# 3 information features\n",
    "X,y = make_classification(n_samples=1000, n_features = 25, n_informative=3, n_redundant=2, n_repeated=0, n_classes=8,n_clusters_per_class=1,random_state=0)\n",
    "svc = SVC(kernel = \"linear\")\n",
    "rfecv = RFECV(estimator = svc, step=1, cv = StratifiedKFold(2),scoring='accuracy')\n",
    "rfecv.fit(X,y)\n",
    "\n",
    "print(\"number of best features: %d\" %rfecv.n_features_ )\n",
    "print(\"feature size: %s, support: %s\" %(np.shape(rfecv.support_), rfecv.support_))\n",
    "rfecv.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection using SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new feature size:  (150, 3)\n",
      "[ True  True  True False]\n",
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]]\n",
      "[[ 5.1  3.5  1.4]\n",
      " [ 4.9  3.   1.4]\n",
      " [ 4.7  3.2  1.3]\n",
      " [ 4.6  3.1  1.5]\n",
      " [ 5.   3.6  1.4]]\n"
     ]
    }
   ],
   "source": [
    "# L1 based feature selection\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "iris = load_iris()\n",
    "X,y = iris.data, iris.target\n",
    "X.shape\n",
    "lsvc = LinearSVC(C=0.01, penalty='l1',dual=False).fit(X,y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "print(\"new feature size: \",X_new.shape)\n",
    "print(model.get_support())\n",
    "print(X[0:5,:])\n",
    "print(X_new[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08810908  0.06034231  0.39164275  0.45990586]\n"
     ]
    }
   ],
   "source": [
    "# tree based feature selection\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "iris = load_iris()\n",
    "X,y = iris.data, iris.target\n",
    "clf = ExtraTreesClassifier(n_estimators=50)\n",
    "clf=clf.fit(X,y)\n",
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my personal test\n",
    "# removing features with low variance\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "X = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "sel = VarianceThreshold(threshold=(0.8*(1-0.8)))\n",
    "sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# univariate feature selection\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X.shape\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=StratifiedKFold(n_splits=2, random_state=None, shuffle=False),\n",
       "   estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "   n_jobs=1, scoring='accuracy', step=1, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X,y = make_classification(n_samples=1000, n_features=25,n_informative=3,n_redundant=2,n_repeated=0,n_classes=8,\n",
    "                         n_clusters_per_class=1, random_state=0)\n",
    "svc = SVC(kernel = \"linear\")\n",
    "rfecv = RFECV(estimator=svc, step=1,cv=StratifiedKFold(2),scoring='accuracy')\n",
    "rfecv.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

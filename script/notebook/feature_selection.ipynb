{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mainly https://machinelearningmastery.com/feature-selection-in-python-with-scikit-learn/\n",
    "# https://www.cnblogs.com/hhh5460/p/5186226.html\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import pandas\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "# prepare my dataset\n",
    "file_path = \"./original_train_and_test\"\n",
    "f = open(file_path, 'r')\n",
    "# get whole line data\n",
    "lists = []\n",
    "for line in f.readlines():\n",
    "    list_split = line.rstrip('\\n').rstrip(' ')\n",
    "    lists.append(list_split)\n",
    "# split, no need to split first one\n",
    "print(len(lists))\n",
    "train_file = []\n",
    "for i in range(len(lists)):\n",
    "    # for every line, we split\n",
    "    temp_line = lists[i]\n",
    "    temp_line = temp_line.split(\" \")\n",
    "    data = []\n",
    "    #in one line, after first column\n",
    "    for j in range(len(temp_line)):\n",
    "        # split this, mainly \"2:33\", like this\n",
    "        temp_line_column = temp_line[j]\n",
    "        temp_line_column = temp_line_column.split(\":\")\n",
    "        data.append(np.double(temp_line_column[-1]))\n",
    "    train_file.append(data)\n",
    "f.close()\n",
    "train_file=np.array(train_file)\n",
    "data = train_file[:,1:]\n",
    "target = train_file[:,0]\n",
    "print(np.shape(target),\" \", np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa= np.array([[1,2,3],[4,5,6]])\n",
    "print(np.repeat(list(range(0,4)), 5))\n",
    "list(range(0,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "print(\"data shape: \",np.shape(array))\n",
    "X= array[:,0:8]\n",
    "Y=array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive feature elimination\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(dataset.data, dataset.target)\n",
    "print(np.shape(dataset.data))\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n",
      "[0.01623481 0.04912343 0.00743101 0.00485221 0.0074714  0.0315217\n",
      " 0.00603733 0.01229947 0.00782881 0.0036983  0.00401372 0.00709569\n",
      " 0.00195402 0.00753202 0.01753694 0.011078   0.01266701 0.00778824\n",
      " 0.00993096 0.01052091 0.01717294 0.00935443 0.00686612 0.00710627\n",
      " 0.0105215  0.00502483 0.01211754 0.01644857 0.02261324 0.01681669\n",
      " 0.01260911 0.00975306 0.00603746 0.01184127 0.01337936 0.00377632\n",
      " 0.00619414 0.003557   0.00765417 0.00495942 0.01333613 0.00440796\n",
      " 0.01599379 0.00571577 0.00315051 0.00504152 0.01277445 0.00406658\n",
      " 0.00486334 0.00396868 0.01299135 0.00356714 0.00239822 0.00248487\n",
      " 0.00230314 0.00496607 0.00465496 0.00432965 0.00244171 0.03735858\n",
      " 0.01736126 0.02104979 0.03259693 0.00752627 0.00368842 0.02263868\n",
      " 0.00256847 0.00570476 0.01031523 0.00706142 0.01512314 0.00476497\n",
      " 0.00691163 0.00628387 0.08863991 0.00264872 0.00711556 0.00710685\n",
      " 0.10049    0.01123719 0.00586871 0.00862491 0.00385427 0.0054935\n",
      " 0.00102526 0.00306646]\n",
      "[0.00102526 0.00195402 0.00230314 0.00239822 0.00244171 0.00248487\n",
      " 0.00256847 0.00264872 0.00306646 0.00315051 0.003557   0.00356714\n",
      " 0.00368842 0.0036983  0.00377632 0.00385427 0.00396868 0.00401372\n",
      " 0.00406658 0.00432965 0.00440796 0.00465496 0.00476497 0.00485221\n",
      " 0.00486334 0.00495942 0.00496607 0.00502483 0.00504152 0.0054935\n",
      " 0.00570476 0.00571577 0.00586871 0.00603733 0.00603746 0.00619414\n",
      " 0.00628387 0.00686612 0.00691163 0.00706142 0.00709569 0.00710627\n",
      " 0.00710685 0.00711556 0.00743101 0.0074714  0.00752627 0.00753202\n",
      " 0.00765417 0.00778824 0.00782881 0.00862491 0.00935443 0.00975306\n",
      " 0.00993096 0.01031523 0.01052091 0.0105215  0.011078   0.01123719\n",
      " 0.01184127 0.01211754 0.01229947 0.01260911 0.01266701 0.01277445\n",
      " 0.01299135 0.01333613 0.01337936 0.01512314 0.01599379 0.01623481\n",
      " 0.01644857 0.01681669 0.01717294 0.01736126 0.01753694 0.02104979\n",
      " 0.02261324 0.02263868 0.0315217  0.03259693 0.03735858 0.04912343\n",
      " 0.08863991 0.10049   ]\n",
      "[84 12 54 52 58 53 66 75 85 44 37 51 64  9 35 82 49 10 47 57 41 56 71  3\n",
      " 48 39 55 25 45 83 67 43 80  6 32 36 73 22 72 69 11 23 77 76  2  4 63 13\n",
      " 38 17  8 81 21 31 18 68 19 24 15 79 33 26  7 30 16 46 50 40 34 70 42  0\n",
      " 27 29 20 60 14 61 28 65  5 62 59  1 74 78]\n"
     ]
    }
   ],
   "source": [
    "#feature importance\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "dataset = datasets.load_iris()\n",
    "print(np.shape(dataset.data), np.shape(dataset.target))\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(data, target)\n",
    "\n",
    "print(model.feature_importances_)\n",
    "importances = model.feature_importances_\n",
    "print(np.sort(importances))\n",
    "print(np.argsort(importances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True False False  True\n",
      " False  True  True False  True  True  True False  True False  True  True\n",
      "  True  True  True  True  True  True False  True  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True False  True  True  True  True\n",
      "  True  True False False False  True False  True False  True False False\n",
      " False  True  True False  True  True  True False  True  True False  True\n",
      " False False]\n",
      "[ 1  1  1  1  1  1  1  1  1 23 21  1 22  1  1 16  1  1  1 12  1  8  1  1\n",
      "  1  1  1  1  1  1 13  1  1  9  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  6  1  1  1  1  1  1 15  3  5  1 18  1 11  1 10 14\n",
      "  7  1  1  4  1  1  1 17  1  1  2  1 20 19]\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "model = SGDClassifier()\n",
    "rfe = RFE(model, 64)\n",
    "rfe = rfe.fit(data, target)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.56096045e-01 3.57303979e-02 5.24574294e-03 1.64070013e-03\n",
      " 3.38424769e-04 2.10381469e-04 1.13915998e-04 8.54709480e-05\n",
      " 8.26878705e-05 6.46105662e-05 6.10110765e-05 4.62972789e-05\n",
      " 3.30533824e-05 3.19323599e-05 2.85969306e-05 2.65137323e-05\n",
      " 2.13527640e-05 1.95335368e-05 1.72473325e-05 1.51837963e-05\n",
      " 1.39119411e-05 1.09729136e-05 1.05160885e-05 9.33864455e-06\n",
      " 8.24714744e-06 7.36106294e-06 6.48593850e-06 5.78778528e-06\n",
      " 5.25927942e-06 4.91191971e-06 3.10358683e-06 2.12582678e-06\n",
      " 1.25210909e-06 9.23644939e-07 2.98937909e-07 1.63748722e-07\n",
      " 5.98533461e-08 5.77049706e-08 1.89763513e-08 1.83332102e-08\n",
      " 1.02643022e-08 9.17874445e-09 8.80594614e-09 5.98677206e-09\n",
      " 5.83504236e-09 4.60506958e-09 4.06006100e-09 3.68192789e-09\n",
      " 3.60168711e-09 2.96257406e-09 2.56895922e-09 2.42584711e-09\n",
      " 2.27616476e-09 2.21709374e-09 1.88928909e-09 1.62178042e-09\n",
      " 1.56798290e-09 1.38883495e-09 1.12192291e-09 1.06763333e-09\n",
      " 1.03054445e-09 9.31325386e-10 8.29021293e-10 6.93292570e-10\n",
      " 6.39316928e-10 5.44562343e-10 5.18844282e-10 4.65486659e-10\n",
      " 3.93367298e-10 3.36409462e-10 3.00855472e-10 1.82482908e-10\n",
      " 1.59187347e-10 1.33262915e-10 1.28823740e-10 9.69026917e-11\n",
      " 7.23157330e-15 5.66701655e-15 3.76636989e-15 2.14396164e-21\n",
      " 1.72052559e-21 1.53132749e-21 1.26567296e-21 6.94458316e-22\n",
      " 3.51340738e-22 1.60497204e-34]\n",
      "[1.60497204e-34 3.51340738e-22 6.94458316e-22 1.26567296e-21\n",
      " 1.53132749e-21 1.72052559e-21 2.14396164e-21 3.76636989e-15\n",
      " 5.66701655e-15 7.23157330e-15 9.69026917e-11 1.28823740e-10\n",
      " 1.33262915e-10 1.59187347e-10 1.82482908e-10 3.00855472e-10\n",
      " 3.36409462e-10 3.93367298e-10 4.65486659e-10 5.18844282e-10\n",
      " 5.44562343e-10 6.39316928e-10 6.93292570e-10 8.29021293e-10\n",
      " 9.31325386e-10 1.03054445e-09 1.06763333e-09 1.12192291e-09\n",
      " 1.38883495e-09 1.56798290e-09 1.62178042e-09 1.88928909e-09\n",
      " 2.21709374e-09 2.27616476e-09 2.42584711e-09 2.56895922e-09\n",
      " 2.96257406e-09 3.60168711e-09 3.68192789e-09 4.06006100e-09\n",
      " 4.60506958e-09 5.83504236e-09 5.98677206e-09 8.80594614e-09\n",
      " 9.17874445e-09 1.02643022e-08 1.83332102e-08 1.89763513e-08\n",
      " 5.77049706e-08 5.98533461e-08 1.63748722e-07 2.98937909e-07\n",
      " 9.23644939e-07 1.25210909e-06 2.12582678e-06 3.10358683e-06\n",
      " 4.91191971e-06 5.25927942e-06 5.78778528e-06 6.48593850e-06\n",
      " 7.36106294e-06 8.24714744e-06 9.33864455e-06 1.05160885e-05\n",
      " 1.09729136e-05 1.39119411e-05 1.51837963e-05 1.72473325e-05\n",
      " 1.95335368e-05 2.13527640e-05 2.65137323e-05 2.85969306e-05\n",
      " 3.19323599e-05 3.30533824e-05 4.62972789e-05 6.10110765e-05\n",
      " 6.46105662e-05 8.26878705e-05 8.54709480e-05 1.13915998e-04\n",
      " 2.10381469e-04 3.38424769e-04 1.64070013e-03 5.24574294e-03\n",
      " 3.57303979e-02 9.56096045e-01]\n",
      "[85 84 83 82 81 80 79 78 77 76 75 74 73 72 71 70 69 68 67 66 65 64 63 62\n",
      " 61 60 59 58 57 56 55 54 53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38\n",
      " 37 36 35 34 33 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14\n",
      " 13 12 11 10  9  8  7  6  5  4  3  2  1  0]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "# pca learning\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca= PCA(n_components = 86)\n",
    "fit=pca.fit(data)\n",
    "print(pca.explained_variance_ratio_)\n",
    "importances = pca.explained_variance_ratio_\n",
    "print(np.sort(importances))\n",
    "print(np.argsort(importances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43  9 10  3 19 20 15 66 11 79 78  1 80  1 51 41 33 76 63 64 55 61 62 39\n",
      " 32 58 29 37 31 40 49 56 60 57 23  8  6 22 26 18  7 17  2 14 13 21  1 24\n",
      " 16 45  5 12  4  1  1 44 25  1 36  1 34 27 68 48 71 46 74 77 47 53 73 59\n",
      " 67 65 30 70 52 54 28 42 72 35 38 50 69 75]\n",
      "[53 54 46 57 59 13 11 42  3 52 50 36 40 35  1  2  8 51 44 43  6 48 41 39\n",
      "  4  5 45 37 34 47 56 38 61 78 26 74 28 24 16 60 81 58 27 82 23 29 15 79\n",
      "  0 55 49 65 68 63 30 83 14 76 69 77 20 31 33 25 71 32 21 22 18 19 73  7\n",
      " 72 62 84 75 64 80 70 66 85 17 67 10  9 12]\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# 3 information features\n",
    "X,y = make_classification(n_samples=1000, n_features = 25, n_informative=3, n_redundant=2, n_repeated=0, n_classes=8,n_clusters_per_class=1,random_state=0)\n",
    "svc = SVC(kernel = \"linear\")\n",
    "rfecv = RFECV(estimator = svc, step=1, cv = StratifiedKFold(2),scoring='accuracy')\n",
    "rfecv.fit(data[1:len(data):30],target[1:len(data):30])\n",
    "\n",
    "print(rfecv.ranking_)\n",
    "print(np.argsort(rfecv.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new feature size:  (1851, 31)\n",
      "[ True  True  True False  True  True  True False  True False False  True\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False  True  True\n",
      " False  True  True False False  True  True  True  True False  True  True\n",
      "  True  True  True  True False  True False  True  True  True  True  True\n",
      "  True  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False]\n"
     ]
    }
   ],
   "source": [
    "# L1 based feature selection\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "X,y = data,target\n",
    "X.shape\n",
    "lsvc = LinearSVC(C=0.01, penalty='l1',dual=False).fit(X,y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "print(\"new feature size: \",X_new.shape)\n",
    "print(model.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00844524 0.00815672 0.00691427 0.00664265 0.01377251 0.0173468\n",
      " 0.00979804 0.0134566  0.01243295 0.0034522  0.00311748 0.01066331\n",
      " 0.00310558 0.00798139 0.0137096  0.00958568 0.02340886 0.01527195\n",
      " 0.00849646 0.01098588 0.01739929 0.00985057 0.01604118 0.01419329\n",
      " 0.01685137 0.00931471 0.01069027 0.01260729 0.01076021 0.01203758\n",
      " 0.01610947 0.01376443 0.01189388 0.01928613 0.00736923 0.00716745\n",
      " 0.00675481 0.00552617 0.00714984 0.00673702 0.00585972 0.00363117\n",
      " 0.00384918 0.00364122 0.00651091 0.00423911 0.00770657 0.00417048\n",
      " 0.00548097 0.00694566 0.00442897 0.00350499 0.00420809 0.00246297\n",
      " 0.00456957 0.0075117  0.00769369 0.00464571 0.00462535 0.03470139\n",
      " 0.02554065 0.01131923 0.00955461 0.00521797 0.00344413 0.02363628\n",
      " 0.00445471 0.0055538  0.00585343 0.01322745 0.0211001  0.00925873\n",
      " 0.00464019 0.01217355 0.03816794 0.01333791 0.00712729 0.00993326\n",
      " 0.1065886  0.00642247 0.0320134  0.04340458 0.00729998 0.00758124\n",
      " 0.00152072 0.00299199]\n",
      "[84 53 85 12 10 64  9 51 41 43 42 47 52 45 50 66 54 58 72 57 63 48 37 67\n",
      " 68 40 79 44  3 39 36  2 49 76 38 35 82 34 55 83 56 46 13  1  0 18 71 25\n",
      " 62 15  6 21 77 11 26 28 19 61 32 29 73  8 27 69 75  7 14 31  4 23 17 22\n",
      " 30 24  5 20 33 70 16 65 60 80 59 74 81 78]\n"
     ]
    }
   ],
   "source": [
    "# tree based feature selection\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "X,y = data,target\n",
    "clf = ExtraTreesClassifier(n_estimators=50)\n",
    "clf=clf.fit(X,y)\n",
    "print(clf.feature_importances_)\n",
    "print(np.argsort(clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# end of my sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True  True  True  True  True  True  True False False  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True False False\n",
      " False  True False False False False False  True  True False False False\n",
      " False False  True  True  True  True  True False  True  True False  True\n",
      " False False  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False]\n",
      "[17  1  1  1  1  1  1  1  1 23 16  1 21  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1 18 10 20  1 14 22 15  7 12  1  1 13  9 11\n",
      " 19  4  1  1  1  1  1  2  1  1  3  1  5  8  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  6]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n",
      "[ 0.117  0.068  0.403  0.412]\n"
     ]
    }
   ],
   "source": [
    "#feature importance\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "dataset = datasets.load_iris()\n",
    "print(np.shape(dataset.data), np.shape(dataset.target))\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(dataset.data, dataset.target)\n",
    "\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/feature-selection-machine-learning-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  111.52   1411.887    17.605    53.108  2175.565   127.669     5.393\n",
      "   181.304]\n",
      "[[  6.000e+00   1.480e+02   7.200e+01   3.500e+01   0.000e+00   3.360e+01\n",
      "    6.270e-01   5.000e+01]\n",
      " [  1.000e+00   8.500e+01   6.600e+01   2.900e+01   0.000e+00   2.660e+01\n",
      "    3.510e-01   3.100e+01]\n",
      " [  8.000e+00   1.830e+02   6.400e+01   0.000e+00   0.000e+00   2.330e+01\n",
      "    6.720e-01   3.200e+01]\n",
      " [  1.000e+00   8.900e+01   6.600e+01   2.300e+01   9.400e+01   2.810e+01\n",
      "    1.670e-01   2.100e+01]\n",
      " [  0.000e+00   1.370e+02   4.000e+01   3.500e+01   1.680e+02   4.310e+01\n",
      "    2.288e+00   3.300e+01]]\n",
      "[[ 148.    0.   50.]\n",
      " [  85.    0.   31.]\n",
      " [ 183.    0.   32.]\n",
      " [  89.   94.   21.]\n",
      " [ 137.  168.   33.]]\n"
     ]
    }
   ],
   "source": [
    "#univariate selection\n",
    "import pandas\n",
    "import numpy\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#feature extraction\n",
    "test = SelectKBest(score_func = chi2, k=3)\n",
    "fit = test.fit(X, Y)\n",
    "# fit = test.fit(dataset.data, dataset.target)\n",
    "# summarize scores\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "features = fit.transform(X)\n",
    "print(X[0:5,:])\n",
    "#after transformation, just select those features that have maximum scores\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of features: 3\n",
      "selected features: [ True False False False False  True  True False]\n",
      "feature ranking: [1 2 3 5 6 1 1 4]\n"
     ]
    }
   ],
   "source": [
    "# recursive feature elimination\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, Y)\n",
    "print((\"num of features: %d\")%fit.n_features_)\n",
    "print((\"selected features: %s\")%fit.support_)\n",
    "print((\"feature ranking: %s\")%fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88854663 0.06159078 0.02579012]\n"
     ]
    }
   ],
   "source": [
    "# pca learning\n",
    "\n",
    "# pca\n",
    "import numpy\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca= PCA(n_components = 3)\n",
    "fit=pca.fit(X)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.117  0.223  0.104  0.082  0.071  0.139  0.11   0.154]\n"
     ]
    }
   ],
   "source": [
    "# feature importance\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, Y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "#  this is overall method\n",
    "## http://scikit-learn.org/stable/modules/feature_selection.html\n",
    "\n",
    "- remove features with low variances\n",
    "- univariate feature selection\n",
    "- Recursive feature elimination\n",
    "- feature selection using SelectFromModel\n",
    "    - L1- based feature selection\n",
    "    - tree-based feature selection\n",
    "- sfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 1]\n",
      " [0 1 0]\n",
      " [0 1 1]]\n",
      "(6, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove features with low variances\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "X = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "print(np.array(X))\n",
    "print(np.shape(X))\n",
    "sel=VarianceThreshold()\n",
    "# sel=VarianceThreshold(threshold=(0.8*(1-0.8)))\n",
    "sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]]\n",
      "(150, 2)\n",
      "[[ 1.4  0.2]\n",
      " [ 1.4  0.2]\n",
      " [ 1.3  0.2]\n",
      " [ 1.5  0.2]\n",
      " [ 1.4  0.2]]\n"
     ]
    }
   ],
   "source": [
    "# univariate feature selection\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "iris = load_iris()\n",
    "X,y = iris.data, iris.target\n",
    "print(X.shape)\n",
    "print(X[0:5,:])\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(X,y)\n",
    "print(X_new.shape)\n",
    "print(X_new[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "[False  True  True  True]\n",
      "[2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Recursive feature elimination, no cross validation\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(dataset.data, dataset.target)\n",
    "print(np.shape(dataset.data))\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of best features: 3\n",
      "feature size: (25,), support: [False  True False False False False False  True False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 5,  1, 12, 19, 15,  6, 17,  1,  2, 21, 23, 11, 16, 10, 13, 22,  8,\n",
       "       14,  1, 20,  7,  9,  3,  4, 18])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# 3 information features\n",
    "X,y = make_classification(n_samples=1000, n_features = 25, n_informative=3, n_redundant=2, n_repeated=0, n_classes=8,n_clusters_per_class=1,random_state=0)\n",
    "svc = SVC(kernel = \"linear\")\n",
    "rfecv = RFECV(estimator = svc, step=1, cv = StratifiedKFold(2),scoring='accuracy')\n",
    "rfecv.fit(X,y)\n",
    "\n",
    "print(\"number of best features: %d\" %rfecv.n_features_ )\n",
    "print(\"feature size: %s, support: %s\" %(np.shape(rfecv.support_), rfecv.support_))\n",
    "rfecv.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection using SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new feature size:  (150, 3)\n",
      "[ True  True  True False]\n",
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]]\n",
      "[[ 5.1  3.5  1.4]\n",
      " [ 4.9  3.   1.4]\n",
      " [ 4.7  3.2  1.3]\n",
      " [ 4.6  3.1  1.5]\n",
      " [ 5.   3.6  1.4]]\n"
     ]
    }
   ],
   "source": [
    "# L1 based feature selection\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "iris = load_iris()\n",
    "X,y = iris.data, iris.target\n",
    "X.shape\n",
    "lsvc = LinearSVC(C=0.01, penalty='l1',dual=False).fit(X,y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "print(\"new feature size: \",X_new.shape)\n",
    "print(model.get_support())\n",
    "print(X[0:5,:])\n",
    "print(X_new[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08810908  0.06034231  0.39164275  0.45990586]\n"
     ]
    }
   ],
   "source": [
    "# tree based feature selection\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "iris = load_iris()\n",
    "X,y = iris.data, iris.target\n",
    "clf = ExtraTreesClassifier(n_estimators=50)\n",
    "clf=clf.fit(X,y)\n",
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my personal test\n",
    "# removing features with low variance\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "X = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "sel = VarianceThreshold(threshold=(0.8*(1-0.8)))\n",
    "sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# univariate feature selection\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X.shape\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=StratifiedKFold(n_splits=2, random_state=None, shuffle=False),\n",
       "   estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "   n_jobs=1, scoring='accuracy', step=1, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X,y = make_classification(n_samples=1000, n_features=25,n_informative=3,n_redundant=2,n_repeated=0,n_classes=8,\n",
    "                         n_clusters_per_class=1, random_state=0)\n",
    "svc = SVC(kernel = \"linear\")\n",
    "rfecv = RFECV(estimator=svc, step=1,cv=StratifiedKFold(2),scoring='accuracy')\n",
    "rfecv.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
